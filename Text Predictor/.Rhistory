predict(fit,newdata = testSA[4,])
fit<-train((chd)~age+alcohol+obesity+tobacco+typea+ldl,family="binomial",method="glm",data=trainSA)
predict(fit,newdata = testSA[1,])
testSA[1,]
predict(fit,newdata = testSA[2,])
testSA[2,]
summary(fit)
missClass = function(trainSA,predict(fit,newdata=trainSA)){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass = function(values=trainSA$chd,prediction=predict(fit,newdata=trainSA)){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass()
missClass
missClass()
missClass = function(values=testSA$chd,prediction=predict(fit,newdata=testSA)){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass()
fit<-train(factor(chd)~age+alcohol+obesity+tobacco+typea+ldl,family="binomial",method="glm",data=trainSA)
missClass = function(values=trainSA$chd,prediction=predict(fit,newdata=trainSA)){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass()
missClass = function(values=trainSA$chd,prediction=predict(fit,newdata=trainSA)){sum((prediction== factor(values))/length(values)}
missClass = function(values=trainSA$chd,prediction=predict(fit,newdata=trainSA)){sum((prediction==factor(values)))/length(factor(values))}
missClass()
1-missClass()
missClass = function(values=trainSA$chd,prediction=predict(fit,newdata=trainSA)){sum((prediction!=factor(values))/length(values)}
missClass = function(values=trainSA$chd,prediction=predict(fit,newdata=trainSA)){sum((prediction!=factor(values)))/length(factor(values))}
missClass()
data(vowel.train)
data(vowel.test)
head(vowel.train)
?randomforest
?randomForest
fit<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
library(randomForest)
fit<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
fit<-randomForest(y~.,data=vowel.train)
summary(fit)
print(fit)
varImp(fit,scale=FALSE)
varImp(fit)
?varImp
varImp(fit$forest)
print(importance(fit,type = 2))
order(print(importance(fit,type = 2)))
order(print(importance(fit,type = 2)))$IncNodePurity
varImp(fit)
fit<-randomForest(y~.,data=vowel.train, importance=TRUE
)
fit<-randomForest(y~.,data=vowel.train, importance=TRUE)
varImp(fit)
x<-varimp(fit)
x<-varImp(fit)
order(x$Overall)
x[order(x$Overall),]
x[order(desc(x$Overall)),]
x[-order(x$Overall),]
x[order(x$Overall),]
x
order(x$Overall)
set.seed(33833)
fit<-randomForest(y~.,data=vowel.train, importance=TRUE)
varImp(fit)
order(x$Overall)
varImp(fit,scale=FALSE)
fit<-train(y~.,data=vowel.train, importance=TRUE,method="rf")
fit<-randomForest(y~.,data=vowel.train, importance=TRUE)
varImp(fit)
order(varImp(fit))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train    )
unique(vowel.train$y)
vowel.train<-data.frame(vowel.train[,2:11],as.factor(vowel.train[,1]))
str(vowel.train)
data("vowel.train")
vowel.train<-data.frame(vowel.train[,2:11],y=as.factor(vowel.train[,1]))
data("vowel.train")
vowel.train<-data.frame(vowel.train[,2:11],y=as.factor(vowel.train[,1]))
str(vowel.train)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train<-data.frame(vowel.train[,2:11],y=as.factor(vowel.train[,1]))
vowel.test<-data.frame(vowel.test[,2:11],y=as.factor(vowel.test[,1]))
fit1<-train(y~.,data=vowel.train,method="rf")
fit2<-train(y~.,data=vowel.train,method="gbm")
summary(fit1)
print(fit1$finalModel)
print(fit2$finalModel)
summary(fit2)
print(fit2)
str(vowel.test)
pred1<-predict(fit1,newdata = vowel.test)
table(vowel.test$y,pred1)
confusionMatrix(vowel.test$y,pred1)
pred2<-predict(fit2,newdata = vowel.test)
table(vowel.test$y,pred2)
confusionMatrix(vowel.test$y,pred2)
predDF<-data.frame(pred1,pred2,y=vowel.test$y)
combfit<-train(y~.,method="gam",data=predDF)
preddf<-predict(combfit,data=predDF)
confusionMatrix(preddf,vowel.test$y)
table(preddf,vowel.test$y)
warnings()
Accuracy = function(values,prediction1,prediction2){
sum((prediction1==values)&&(prediction2==values))/length(values)
}
Accuracy(vowel.test$y,pred1,pred2)
Accuracy = function(values,prediction1){
sum(prediction1==values)/length(values)
}
Accuracy(vowel.test$y,pred1)
Accuracy(vowel.test$y,pred2)
Accuracy = function(values,prediction1,prediction2){
sum((prediction1==values)||(prediction2==values))/length(values)
}
Accuracy(vowel.test$y,pred1,pred2)
Accuracy = function(values,prediction1,prediction2){
sum((prediction1==values)*1*(prediction2==values)*1)/length(values)
}
Accuracy(vowel.test$y,pred1,pred2)
Accuracy = function(values,prediction1,prediction2){
sum((prediction1==values)*(prediction2==values))/length(values)
}
Accuracy(vowel.test$y,pred1,pred2)
table(pred1,vowel.test$y)
table(pred1,pred2)
confusionMatrix(pred1,pred2)
table(pred1,pred2,vowel.test$y)
length(vowel.test$y)
sum(vowel.test$y==pred1)
sum(vowel.test$y==pred2)
sum((vowel.test$y==pred2)&&(vowel.test$y==pred1))
sum((vowel.test$y==pred2)*(vowel.test$y==pred1))
table1<-table(pred1,vowel.test$y)
table2<-table(pred2,vowel.test$y)
table1
table2
table1+table2
diag(table1+table())
diag(table1+table2)
sum(diag(table1+table2))
521/(462*2)
diag(table1)
diag(table2)
30+20+12+21+13+23+27+29+24+18+4
221/462
Accuracy(vowel.test$y,pred1,pred2)
table1<-table(pred1,vowel.test$y)
table1
table1<-table(vowel.test$y,pred1)
table1
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1==values){
if(prediction2==values)
sum<sum+1
}
}
sum
}
Accuracy(vowel.test$y,pred1,pred2)
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1==values){
if(prediction2==values)
sum<-sum+1
}
}
sum
}
Accuracy(vowel.test$y,pred1,pred2)
warning()
warnings()
Accuracy(vowel.test$y,pred1,pred2)
warnings()
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1==values){
if(prediction2==values){
sum<-sum+1
}
}
}
sum
}
Accuracy(vowel.test$y,pred1,pred2)
warnings()
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if else(prediction1==values){
if else(prediction2==values){
sum<-sum+1
}
}
}
sum
}
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if (prediction1=values){
if(prediction2=values){
sum<-sum+1
}
}
}
sum
}
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1=values){
if(prediction2=values){
sum<-sum+1
}
}
}
sum
}
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1=values){
if(prediction2=values){
sum<-sum+1
}
}
}
sum
}
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1==values){
if(prediction2==values){
sum<-sum+1
}
}
}
sum
}
Accuracy(vowel.test$y,pred1,pred2)
warnings()
Accuracy = function(values,prediction1,prediction2){
sum<-0
for(i in 1:length(values)){
if(prediction1[i]==values[i]){
if(prediction2[i]==values[i]){
sum<-sum+1
}
}
}
sum
}
warnings()
Accuracy(vowel.test$y,pred1,pred2)
Accuracy(vowel.test$y,pred2,pred1)
199/462
199*2
199*2/462
.63*463
.63*462
Accuracy1 = function(values,prediction1,prediction2){
sum((prediction1!=values)*(prediction2!=values))/length(values)
}
Accuracy1(vowel.test$y,pred1,pred2)
1-.3030303
URL1="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
if (!file.exists("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-training.csv")) {
download.file(URL1, destfile = "C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-training.csv")
}
URL2="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-testing.csv")) {
download.file(URL1, destfile = "C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-testing.csv")
}
Traindata<-read.csv("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-training.csv", stringsAsFactors = FALSE)
Testdata<-read.csv("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-testing.csv", stringsAsFactors = FALSE)
```
##Split the Train data
Splitter<-Traindata$raw_timestamp_part_1
TrainSplit<-split(Traindata,Splitter)
mutate_func<-function(x){as.data.frame(x)%>%mutate(Window=
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[2],1,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[3],2,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[4], 3,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[5],4,5)))))}
TrainSplittr<-lapply(TrainSplit,mutate_func)
##recombine back to a dataframe
TraindataMod<-as.data.frame(NULL)
for( i in 1:length(TrainSplittr)){
x<-as.data.frame(TrainSplittr[[i]])
TraindataMod<-rbind(TraindataMod,x)
}
## Create the training data set retaining only the predictors
TrainingData<-TraindataMod[,-c(1,2,3,4,5,6,7)]
## Remove near zero variance
TrainingData<-TrainingData[,-nearZeroVar(TrainingData)]
## Create 10 folds for cross validation
folds<-createFolds(y=TrainingData$classe,k=10,list=TRUE,returnTrain = TRUE)
library(dplyr)
library(caret)
library(RANN)
##Split the Train data
Splitter<-Traindata$raw_timestamp_part_1
TrainSplit<-split(Traindata,Splitter)
mutate_func<-function(x){as.data.frame(x)%>%mutate(Window=
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[2],1,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[3],2,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[4], 3,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[5],4,5)))))}
TrainSplittr<-lapply(TrainSplit,mutate_func)
##recombine back to a dataframe
TraindataMod<-as.data.frame(NULL)
for( i in 1:length(TrainSplittr)){
x<-as.data.frame(TrainSplittr[[i]])
TraindataMod<-rbind(TraindataMod,x)
}
## Create the training data set retaining only the predictors
TrainingData<-TraindataMod[,-c(1,2,3,4,5,6,7)]
## Remove near zero variance
TrainingData<-TrainingData[,-nearZeroVar(TrainingData)]
## Create 10 folds for cross validation
folds<-createFolds(y=TrainingData$classe,k=10,list=TRUE,returnTrain = TRUE)
## Preprocess each fold by scaling, centering, imputing nearest neighbours
set.seed(12342)
PreProc<-preProcess(TrainingData[,-94],method=c("center","scale","knnImpute"))
x<-predict(PreProc,TrainingData[,-94])
head(x,1)
mean(x$roll_belt)
sd(x$roll_belt)
sd(x$Window)
mean(x$Window)
table(is.na(x))
TrainingDataProcessed<-x
folds<-createFolds(y=TrainingDataProcessed$classe,k=10,list=TRUE,returnTrain = TRUE)
library(caret)
folds<-createFolds(y=TrainingDataProcessed$classe,k=10,list=TRUE,returnTrain = TRUE)
TrainingDataProcessed<-as.data.frame(TrainingDataProcessed,classe=TrainingData$classe)
dim(TrainingDataProcessed)
TrainingDataProcessed<-cbind(TrainingDataProcessed,classe=TrainingData$classe)
TrainingDataProcessed$classe
folds<-createFolds(y=TrainingDataProcessed$classe,k=10,list=TRUE,returnTrain = TRUE)
args(trainControl)
fitControl<-trainControl(method = "cv",number = 10)
fit<-train(classe~.,method="rf",trControl=fitControl,data=TrainingDataProcessed)
highcorrelation<-findCorrelation(TrainingDataProcessed,cutoff = .75)
Correlationmatrix<-cor(TrainingDataProcessed)
names(TrainingDataProcessed)
Correlationmatrix<-cor(TrainingDataProcessed[,-c(95)])
upper.tri(Correlationmatrix)
?upper.tri
highcorrelation<-findCorrelation(Correlationmatrix,cutoff = .75)
table(highcorrelation)
summary(Correlationmatrix)
summary(Correlationmatrix[upper.tri(Correlationmatrix)])
highcorrelation<-findCorrelation(Correlationmatrix,cutoff = .75)
?findCorrelation
highcorrelation<-findCorrelation(Correlationmatrix,cutoff = .75,verbose = TRUE,names=TRUE)
names(TrainingDataProcessed[,highcorrelation])
names(TrainingDataProcessed[,-highcorrelation])
highcorrelation<-findCorrelation(Correlationmatrix,cutoff = .75)
highcorrelation<-findCorrelation(Correlationmatrix,cutoff = .75,verbose = TRUE,names=TRUE)
highcorrelation
highcorrelation<-findCorrelation(Correlationmatrix,cutoff = .75,verbose = TRUE)
TrainingDataProcessedCorRem<-TrainingDataProcessed[,-highcorrelation]
Correlationmatrix<-cor(TrainingDataProcessedCorRem)
Correlationmatrix<-cor(TrainingDataProcessedCorRem[,-51])
summary(Correlationmatrix[upper.tri(Correlationmatrix)])
fit<-train(classe~.,method="rf",trControl=fitControl,data=TrainingDataProcessedCorRem)
summary(fit$finalModel)
print(fit$finalModel)
print(fit)
system.time()
system.time(fit)
fit$modelInfo
fit$results
fit$bestTune
fit$dots
fit$resampledCM
?mtry
?randomForest
fit$results
fittree<-train(classe~.,method="tree",trControl=fitControl,data=TrainingDataProcessedCorRem)
fittree<-train(classe~.,method="rpart",trControl=fitControl,data=TrainingDataProcessedCorRem)
print(fittree)
fitControl2<-trainControl(method = "cvrepeated",number = 10,repeats = 10)
fittree<-train(classe~.,method="rpart",trControl=fitControl,data=TrainingDataProcessedCorRem)
print(fittree)
fitControl2<-trainControl(method = "cvrepeated",number = 100,repeats = 10)
print(fittree)
fittree<-train(classe~.,method="rpart",trControl=fitControl,data=TrainingDataProcessedCorRem)
print(fittree)
fittree<-train(classe~.,method="rpart",trControl=fitControl2,data=TrainingDataProcessedCorRem)
fitControl2<-trainControl(method = "repeatedcv",number = 100,repeats = 10)
fittree<-train(classe~.,method="rpart",trControl=fitControl2,data=TrainingDataProcessedCorRem)
fitControl2<-trainControl(method = "repeatedcv",number = 10,repeats = 10)
fittree<-train(classe~.,method="rpart",trControl=fitControl2,data=TrainingDataProcessedCorRem)
print(fittree)
print(fittree$finalModel)
?rpart
importance<-varImp(fit,scale=FALSE)
plot(importance)
importance
importance[importance>500]
importance[importance$importance>500]
x<-importance[importance$importance>500]
x
x<-importance[importance$calledFrom>500]
c
x
class(importance)
?varImp
arg(varImp())
args(varImp
)
args(varImp)
varImp.randomForest
importance[importance$importance$Overall>500]
x<-importance[importance$importance$Overall>500]
head(x)
x<-importance[importance$importance$Overall>500,]
x<-importance$importance[importance$importance$Overall>500]
importance$importance$Overall>500
importance$importance[importance$importance$Overall>500]
importance[importance$importance$Overall>500,1]
class(importance)
class(as.data.frame(importance))
importance$importance$Overall
importance$model
importance$calledFrom
importance$importance
importance$importance[1:10]
importance$importance[1:10,]
importance$importance[,1:10]
class(importance$importance)
dim(importance$importance)
importance$importance[1]
importance$importance[1:2]
importance$importance[1:2,]
order(importance$importance)
importance1<-varImp(fittree,scale=FALSE)
importance1
print(importance1)
plot(importance1)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(RANN)
URL1="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
if (!file.exists("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-training.csv")) {
download.file(URL1, destfile = "C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-training.csv")
}
URL2="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-testing.csv")) {
download.file(URL1, destfile = "C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-testing.csv")
}
Traindata<-read.csv("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-training.csv", stringsAsFactors = FALSE)
Testdata<-read.csv("C:/Users/Subrata/Coursera/Coursera 8/Week 4/pml-testing.csv", stringsAsFactors = FALSE)
##Split the Train data
Splitter<-Traindata$raw_timestamp_part_1
TrainSplit<-split(Traindata,Splitter)
mutate_func<-function(x){as.data.frame(x)%>%mutate(Window=
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[2],1,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[3],2,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[4], 3,
ifelse(raw_timestamp_part_2<quantile(raw_timestamp_part_2)[5],4,5)))))}
TrainSplittr<-lapply(TrainSplit,mutate_func)
library(shiny)
# Define UI for application that draws a histogram
shinyUI(fluidPage(
# Application title
titlePanel("Old Faithful Geyser Data"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
sliderInput("bins",
"Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Show a plot of the generated distribution
mainPanel(
plotOutput("distPlot")
)
)
))
sessionInfo()
library(shiny)
sessionInfo()
install.packages(c("assertthat", "backports", "BH", "chron", "colorspace", "CORElearn", "curl", "data.table", "DBI", "digest", "gbm", "ggplot2", "htmlTable", "jsonlite", "openssl", "pbkrtest", "proto", "Rcpp", "RcppArmadillo", "RcppEigen", "rmarkdown", "rprojroot", "rsconnect", "RSQLite", "SparseM", "stringi", "stringr", "survival", "swirl", "tibble", "viridis", "XML", "yaml", "zoo"))
rsconnect::setAccountInfo(name='subratasaharia',
token='9F675BC691BC538ABC6AB0B0134AA503',
secret='a8j3AbkduJGfEYGo19tGgeuYmMaEc04GFvuQGHGU')
library(rsconnect)
shiny::runApp('C:/Users/Subrata/Coursera/Coursera 9/Week 4/StockAnalysis')
rsconnect::deployApp('C:/Users/Subrata/Coursera/Coursera 9/Week 4/StockAnalysis')
rsconnect::deployApp('C:/Users/Subrata/Coursera/Coursera 9/Week 4/StockAnalysis')
runApp('C:/Users/Subrata/Coursera/Coursera 9/Week 4/StockAnalysis')
rsconnect::deployApp('C:/Users/Subrata/Coursera/Coursera 9/Week 4/StockAnalysis')
rsconnect::deployApp('C:/Users/Subrata/Coursera/Coursera 9/Week 4/StockAnalysis')
s
q()
source("setwd.R")
setwd("./Capstone/Text Predictor/")
library(shiny)
library(rsconnect)
deployApp()
q()
